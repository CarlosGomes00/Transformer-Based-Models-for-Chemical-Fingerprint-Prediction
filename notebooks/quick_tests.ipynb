{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-23T18:01:00.455190Z",
     "start_time": "2025-09-23T18:00:56.706188Z"
    }
   },
   "source": [
    "from src.data.mgf_tools.mgf_get import mgf_get_spectra\n",
    "from src.utils import calculate_max_num_peaks\n",
    "from src.utils import path_check\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Teste da função para obter o max_num_peaks",
   "id": "8d4449cd12ba8e29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T14:39:33.554465Z",
     "start_time": "2025-09-22T14:39:33.544926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mgf_path = r\"/Users/carla/PycharmProjects/Mestrado/Transformer-Based-Models-for-Chemical-Fingerprint-Prediction/datasets/raw/cleaned_gnps_library.mgf\"\n",
    "\n",
    "path_check(mgf_path)"
   ],
   "id": "7f3dd7d9357af06c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T19:14:42.878234Z",
     "start_time": "2025-09-16T19:13:16.996287Z"
    }
   },
   "cell_type": "code",
   "source": "mgf_data = mgf_get_spectra(mgf_path)",
   "id": "5c91e730e12559b5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T17:46:07.187268Z",
     "start_time": "2025-09-12T17:46:06.996464Z"
    }
   },
   "cell_type": "code",
   "source": "max_num_peaks = calculate_max_num_peaks(mgf_data, percentile=95)",
   "id": "ef670b6c1143dd84",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T17:46:17.592643Z",
     "start_time": "2025-09-12T17:46:17.583085Z"
    }
   },
   "cell_type": "code",
   "source": "print(max_num_peaks)",
   "id": "49faff60dd7d9245",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T19:15:29.645189Z",
     "start_time": "2025-09-16T19:15:22.000077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mz_vocabs = calculate_mz_vocabs(mgf_data)\n",
    "print(mz_vocabs)"
   ],
   "id": "443fb09dabccde6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0000e+00 1.0000e-01 2.0000e-01 ... 4.9718e+03 4.9719e+03 4.9720e+03]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Transformer Class test",
   "id": "66e3ee45d2aea2da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T11:59:18.266603Z",
     "start_time": "2025-09-26T11:58:46.722838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.utils import path_check\n",
    "from src.utils import calculate_mz_vocabs, calculate_max_num_peaks\n",
    "from src.data.data_splitting import preprocess_and_split\n",
    "from src.data.mgf_tools.mgf_get import mgf_get_spectra\n",
    "from src.data.data_loader import data_loader \n",
    "from src.models.Transformer import Transformer"
   ],
   "id": "58ca55ddcacc45ff",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\carla\\miniconda3\\envs\\tese_d_new\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\carla\\miniconda3\\envs\\tese_d_new\\Lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (C:\\Users\\carla\\miniconda3\\envs\\tese_d_new\\Lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "C:\\Users\\carla\\miniconda3\\envs\\tese_d_new\\Lib\\site-packages\\deepmol\\compound_featurization\\__init__.py:20: UserWarning: Mol2Vec not available. Please install it to use it. (pip install git+https://github.com/samoturk/mol2vec#egg=mol2vec)\n",
      "  warnings.warn(\"Mol2Vec not available. Please install it to use it. \"\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T11:59:18.276618Z",
     "start_time": "2025-09-26T11:59:18.269801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mgf_path = r\"/Users/carla/PycharmProjects/Mestrado/Transformer-Based-Models-for-Chemical-Fingerprint-Prediction/datasets/raw/cleaned_gnps_library.mgf\"\n",
    "\n",
    "path_check(mgf_path)"
   ],
   "id": "588ad3de93771f53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T12:02:46.100064Z",
     "start_time": "2025-09-26T11:59:19.158951Z"
    }
   },
   "cell_type": "code",
   "source": "mgf_spectra = mgf_get_spectra(mgf_path, num_spectra=100)",
   "id": "3b2f0a99b88cc206",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T12:02:46.113970Z",
     "start_time": "2025-09-26T12:02:46.102073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_num_peaks = calculate_max_num_peaks(mgf_spectra, percentile=95)\n",
    "mz_vocabs = calculate_mz_vocabs(mgf_spectra)\n",
    "max_seq_len = max_num_peaks + 1\n",
    "vocab_size = len(mz_vocabs)"
   ],
   "id": "3ab0f956c5fc542b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T12:07:10.255072Z",
     "start_time": "2025-09-26T12:07:10.248244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(max_num_peaks)\n",
    "print(vocab_size)"
   ],
   "id": "93e251d6d6d300a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "16051\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T12:06:22.955078Z",
     "start_time": "2025-09-26T12:03:19.928170Z"
    }
   },
   "cell_type": "code",
   "source": "splits = preprocess_and_split(mgf_path, seed=3, num_spectra=100)",
   "id": "f1513aad5e656880",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Loading spectra and SMILES from MGF\n",
      "Loaded 100 spectra from MGF\n",
      "Loaded 100 spectra\n",
      "\n",
      "2. Applying filtering and spectrum processing\n",
      "\n",
      "3. Generating fingerprints for valid spectra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MorganFingerprint: 100%|██████████| 84/84 [00:00<00:00, 497.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Data Splitting\n",
      "Saving splits\n",
      "Split created with seed = 3\n",
      "Train: 67 samples (79.8%)\n",
      "Validation:   8 samples (9.5%)\n",
      "Test:  9 samples (10.7%)\n",
      "Saving fingerprints cache\n",
      "Saved fingerprints cache: 84 samples, 2048 features\n",
      "Files created:\n",
      "  • C:\\Users\\carla\\PycharmProjects\\Mestrado\\Transformer-Based-Models-for-Chemical-Fingerprint-Prediction\\src\\data\\artifacts\\3\\split_ids.pkl\n",
      "  • C:\\Users\\carla\\PycharmProjects\\Mestrado\\Transformer-Based-Models-for-Chemical-Fingerprint-Prediction\\src\\data\\artifacts\\3\\fingerprints.pkl\n",
      "  • C:\\Users\\carla\\PycharmProjects\\Mestrado\\Transformer-Based-Models-for-Chemical-Fingerprint-Prediction\\src\\data\\artifacts\\3\\split_statistics.csv\n",
      "  • C:\\Users\\carla\\PycharmProjects\\Mestrado\\Transformer-Based-Models-for-Chemical-Fingerprint-Prediction\\src\\data\\artifacts\\3\\split_statistics.html\n",
      "Split IDs and Fingerprints saved\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T12:10:42.337267Z",
     "start_time": "2025-09-26T12:07:43.016980Z"
    }
   },
   "cell_type": "code",
   "source": "loaders = data_loader(mgf_path=mgf_path, num_spectra=100, batch_size=4, seed=3, max_num_peaks=max_num_peaks, mz_vocabs=mz_vocabs)",
   "id": "96d6d3c53f80215d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded splits: Train(67), Val(8), Test(9)\n",
      "Filtered to 67 spectra for train\n",
      "Filtered to 8 spectra for val\n",
      "Filtered to 9 spectra for test\n",
      "test DataLoader ready: 9 samples\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T12:11:05.840164Z",
     "start_time": "2025-09-26T12:11:05.832759Z"
    }
   },
   "cell_type": "code",
   "source": "model = Transformer(seed=3,max_seq_len=max_seq_len,vocab_size=vocab_size,morgan_default_dim=2048,d_model=128,n_head=4,num_layers=4,dropout_rate=0.1)",
   "id": "5ce626cf6235c54a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T12:12:03.860627Z",
     "start_time": "2025-09-26T12:11:06.968777Z"
    }
   },
   "cell_type": "code",
   "source": "best_model = model.fit(train_loader=loaders[\"train\"], val_loader=loaders[\"val\"], max_epochs=10)",
   "id": "bb4ac5d1c330e353",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 3\n",
      "C:\\Users\\carla\\miniconda3\\envs\\tese_d_new\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:668: You passed `deterministic=True` and `benchmark=True`. Note that PyTorch ignores torch.backends.cudnn.deterministic=True when torch.backends.cudnn.benchmark=True.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: outputs/logs\\3_train_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | EncoderTransformer | 6.8 M \n",
      "1 | criterion | BCELoss            | 0     \n",
      "-------------------------------------------------\n",
      "6.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.8 M     Total params\n",
      "27.049    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f272e46d18bf4f9aa78ec606927df50d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carla\\miniconda3\\envs\\tese_d_new\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:380: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\NestedTensorImpl.cpp:180.)\n",
      "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n",
      "C:\\Users\\carla\\miniconda3\\envs\\tese_d_new\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 4. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "C:\\Users\\carla\\miniconda3\\envs\\tese_d_new\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:293: The number of training batches (17) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e57f0821457e492e924aa0e702f09d8a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carla\\miniconda3\\envs\\tese_d_new\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 3. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a22a58bc95444a1f98d2fc9ce034e432"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0656c17c59134733a6c08acac433efe5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9c316e5e55c41f283a7f1ee5950b45a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4dc37cf864e1491e9ad87e432de6d01e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c7ddf9423cd443eb609f5d59292a54e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86d0c581072a4900b649896563c92865"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5133a3c639eb41b5b860aeda3f851a63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e2ad59da7624c5395a6b1e72a4700da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6f16821db9545aca2e98b663f281cdd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1599c373079d4faaafe4d60e454a4853"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T12:12:52.042646Z",
     "start_time": "2025-09-26T12:12:51.985677Z"
    }
   },
   "cell_type": "code",
   "source": "model.eval(test_loader=loaders[\"test\"])",
   "id": "a0f0c1a088f524ce",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mbest_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43meval\u001B[49m(test_loader=loaders[\u001B[33m\"\u001B[39m\u001B[33mtest\u001B[39m\u001B[33m\"\u001B[39m])\n",
      "\u001B[31mAttributeError\u001B[39m: 'str' object has no attribute 'eval'"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T12:17:50.835189Z",
     "start_time": "2025-09-26T12:17:50.360686Z"
    }
   },
   "cell_type": "code",
   "source": "model.predict(loaders[\"test\"], return_probabilities=False, save_results=False)",
   "id": "9aa685f7e655bc04",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Device: cuda\n",
      "Return raw probabilities: False\n",
      "Binary threshold: 0.5\n",
      "Predictions made for 9 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "112973581260d921"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
