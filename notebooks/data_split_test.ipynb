{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-04T19:09:42.304912Z",
     "start_time": "2025-08-04T19:09:35.074686Z"
    }
   },
   "source": [
    "from src.data.mgf_tools.mgf_get import *\n",
    "from src.config import *\n",
    "from src.utils import *\n",
    "import pandas as pd\n",
    "from deepmol.splitters import MultiTaskStratifiedSplitter\n",
    "from deepmol.compound_featurization import MorganFingerprint\n",
    "from deepmol.datasets import SmilesDataset\n",
    "from src.config import *"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DATA SPLIT\n",
   "id": "75a59e99f27c56e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T19:09:42.336059Z",
     "start_time": "2025-08-04T19:09:42.333106Z"
    }
   },
   "cell_type": "code",
   "source": "mgf_data = mgf_path\n",
   "id": "2324e2a5bd419a0e",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T19:11:38.444072Z",
     "start_time": "2025-08-04T19:09:42.452759Z"
    }
   },
   "cell_type": "code",
   "source": "spectra = mgf_get_spectra(mgf_data)",
   "id": "8ba6c806f677a792",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T19:11:39.672900Z",
     "start_time": "2025-08-04T19:11:38.466024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "smiles_data = mgf_get_smiles(spectra)\n",
    "\n",
    "smiles_df = pd.DataFrame(smiles_data)"
   ],
   "id": "28481e3f962ce1b7",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T19:31:38.298943Z",
     "start_time": "2025-08-04T19:11:39.687852Z"
    }
   },
   "cell_type": "code",
   "source": "processed_spectra = mgf_deconvoluter(mgf_data=spectra, mz_vocabs=mz_vocabs, min_num_peaks=5, max_num_peaks=max_num_peaks, noise_rmv_threshold=0.01, mass_error=0.01, allowed_spectral_entropy=True, log=False)\n",
   "id": "c05945bbb2f16a05",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T19:31:38.799298Z",
     "start_time": "2025-08-04T19:31:38.316419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spectrum_ids = [spec[0] for spec in processed_spectra]\n",
    "print(f\"Espectros processados: {len(spectrum_ids)}\")\n",
    "\n",
    "filtered_smiles= smiles_df[smiles_df['spectrum_id'].isin(spectrum_ids)]\n",
    "print(f\"SMILES filtrados: {len(filtered_smiles)}\")"
   ],
   "id": "5f798d09fed6e395",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T19:31:38.841275Z",
     "start_time": "2025-08-04T19:31:38.820705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "smiles_list = filtered_smiles['smiles'].tolist()\n",
    "ids_list = filtered_smiles['spectrum_id'].tolist()"
   ],
   "id": "1fc85e58dcdf79bf",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T19:32:24.173073Z",
     "start_time": "2025-08-04T19:31:38.864415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = SmilesDataset(smiles=smiles_list, ids=ids_list)\n",
    "print(f\"Dataset inicial: {len(dataset)} samples\")"
   ],
   "id": "28294b502908893c",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T19:39:36.065375Z",
     "start_time": "2025-08-04T19:32:24.217098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = MorganFingerprint().featurize(dataset)\n",
    "print(f\"Fingerprints gerados: {len(dataset)}\")"
   ],
   "id": "1c2e6f3db97ddbdc",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T19:39:36.219911Z",
     "start_time": "2025-08-04T19:39:36.212999Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.X",
   "id": "7ac09e41240b2ca1",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T19:39:36.236265Z",
     "start_time": "2025-08-04T19:39:36.234057Z"
    }
   },
   "cell_type": "code",
   "source": "dataset._y = dataset.X",
   "id": "d19ecb9fb8f4731e",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T19:39:36.280100Z",
     "start_time": "2025-08-04T19:39:36.276263Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.y",
   "id": "1f93bb0e7f6366e4",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T21:58:59.797791Z",
     "start_time": "2025-08-04T19:39:36.322902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset, val_dataset, test_dataset = MultiTaskStratifiedSplitter().train_valid_test_split(\n",
    "    dataset, frac_train=0.8, frac_val=0.1, frac_test=0.1, seed=0)"
   ],
   "id": "14a657a9b8ac7e89",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T21:58:59.992718Z",
     "start_time": "2025-08-04T21:58:59.988613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"SPLIT\")\n",
    "print(f\"Train: {len(train_dataset)} samples\")\n",
    "print(f\"Validation: {len(val_dataset)} samples\")\n",
    "print(f\"Test: {len(test_dataset)} samples\")"
   ],
   "id": "6c14a2e0d60e2ac",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T21:59:01.672012Z",
     "start_time": "2025-08-04T21:59:01.042039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_stats(y_train: np.ndarray, y_test: np.ndarray, y_val: np.ndarray=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_train : np.ndarray\n",
    "        Labels of the train set\n",
    "    y_test : np.ndarray\n",
    "        Labels of the test set\n",
    "    y_val : np.ndarray, optional\n",
    "        Labels of the validation set, by default None\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[pd.DataFrame, Any]\n",
    "        DataFrame with the stats of the split, styled table\n",
    "    \"\"\"\n",
    "    y_test_sum = np.sum(y_test, axis=0)\n",
    "    y_train_sum = np.sum(y_train, axis=0)\n",
    "\n",
    "    sum_of_all = pd.DataFrame([y_train_sum, y_test_sum], index=[\"train\", \"test\"])\n",
    "\n",
    "    if y_val is not None:\n",
    "        y_val_sum = np.sum(y_val, axis=0)\n",
    "        sum_of_all = pd.DataFrame([y_train_sum, y_test_sum, y_val_sum], index=[\"train\", \"test\", \"validation\"])\n",
    "        sum_of_all.loc['Validation relative split', :] = sum_of_all.loc['validation', :] / (sum_of_all.loc['train', :] + sum_of_all.loc['test', :] + sum_of_all.loc['validation', :]) * 100\n",
    "        sum_of_all.loc['Test relative split', :] = sum_of_all.loc['test', :] / (sum_of_all.loc['train', :] + sum_of_all.loc['test', :]+ sum_of_all.loc['validation', :]) * 100\n",
    "        sum_of_all.loc['Train relative split', :] = sum_of_all.loc['train', :] / (sum_of_all.loc['train', :] + sum_of_all.loc['test', :]+ sum_of_all.loc['validation', :]) * 100\n",
    "\n",
    "    else:\n",
    "        sum_of_all.loc['Test relative split', :] = sum_of_all.loc['test', :] / (sum_of_all.loc['train', :] + sum_of_all.loc['test', :]) * 100\n",
    "        sum_of_all.loc['Train relative split', :] = sum_of_all.loc['train', :] / (sum_of_all.loc['train', :] + sum_of_all.loc['test', :]) * 100\n",
    "\n",
    "    df = pd.melt(sum_of_all.T.reset_index(), id_vars=['index']).rename(columns={'index': 'EC', 'value': 'Percentage of data'})\n",
    "    if y_val is not None:\n",
    "        df = df[(df[\"variable\"]!=\"train\") & (df[\"variable\"]!=\"validation\") & (df[\"variable\"]!=\"test\")]\n",
    "    else: \n",
    "        df = df[(df[\"variable\"]!=\"train\") & (df[\"variable\"]!=\"test\")]\n",
    "\n",
    "    df1 = sum_of_all.loc['Test relative split', :].describe()\n",
    "    df2 = sum_of_all.loc['Train relative split', :].describe()\n",
    "    if y_val is not None:\n",
    "        df3 = sum_of_all.loc['Validation relative split', :].describe()\n",
    "        stats_table = pd.concat([df1, df2, df3], axis=1)\n",
    "    else:\n",
    "        stats_table = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "    stats_table.drop(['count'], inplace=True)\n",
    "    table_styled = stats_table.style.background_gradient(cmap=\"YlGn\")\n",
    "    \n",
    "\n",
    "    return df, table_styled\n",
    "\n",
    "\n",
    "train_labels = train_dataset.y\n",
    "val_labels = val_dataset.y\n",
    "test_labels = test_dataset.y\n",
    "\n",
    "\n",
    "df, table_styled = generate_stats(train_labels, test_labels, val_labels)\n",
    "\n",
    "table_styled"
   ],
   "id": "ad21b4f631869156",
   "execution_count": 15,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
