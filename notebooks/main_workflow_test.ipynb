{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Transformer Model Data Preparation Workflow",
   "id": "9b4d9a25d3fc9dac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This notebook documents the initial pipeline for mass spectrometry data preparation and preprocessing, which is essential for feeding our future Transformer model.\n",
    "\n",
    "We start by loading and processing MGF files, applying a series of filters and transformations to ensure the quality and appropriate format of the data."
   ],
   "id": "6a69d1137df79e62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The first step involves validating the MGF file path (**path_check**) and loading the raw spectra. The **mgf_get_spectra** function is responsible for reading the MGF file and extracting each spectrum's data",
   "id": "cedc79057b837e53"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-01T18:05:22.745508Z",
     "start_time": "2025-08-01T18:05:10.907436Z"
    }
   },
   "source": [
    "from src.utils import *\n",
    "from src.data.flexible_dataloader import *\n",
    "from src.model.transformer import EncoderTransformer"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T18:05:22.750584Z",
     "start_time": "2025-08-01T18:05:22.746513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mgf_data = r\"/Users/carla/PycharmProjects/Mestrado/Transformer-Based-Models-for-Chemical-Fingerprint-Prediction/datasets/raw/cleaned_gnps_library.mgf\"\n",
    "\n",
    "path_check(mgf_data)"
   ],
   "id": "6dca8e4786c6f88c",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T18:07:06.183103Z",
     "start_time": "2025-08-01T18:05:22.751590Z"
    }
   },
   "cell_type": "code",
   "source": "mgf_spect= mgf_get_spectra(mgf_data, num_spectra=10)",
   "id": "a781ab36f38a82b7",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This is the core phase of transforming the raw data. The **mgf_deconvoluter** function iterates over each loaded spectrum, applying a series of cleaning and tokenization steps via the **mgf_spectrum_deconvoluter**",
   "id": "2439e5b290345094"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T18:07:06.257608Z",
     "start_time": "2025-08-01T18:07:06.184116Z"
    }
   },
   "cell_type": "code",
   "source": "x = mgf_deconvoluter(mgf_data=mgf_spect, mz_vocabs=mz_vocabs, min_num_peaks=5, max_num_peaks=max_num_peaks, noise_rmv_threshold=0.01, mass_error=0.01, allowed_spectral_entropy=True, log=True)",
   "id": "aae912e960a915d8",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T18:07:06.265307Z",
     "start_time": "2025-08-01T18:07:06.259614Z"
    }
   },
   "cell_type": "code",
   "source": "print(x)",
   "id": "ddb52c0167e26877",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The **mgf_deconvoluter** function returns a list of tuples, where each tuple (spectrum_id, tokenized_mz, tokenized_precursor, intensities) represents a spectrum that has successfully passed through the entire preprocessing pipeline.",
   "id": "cfb65b4d21c7ecf5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Teste das dimens√µes / formato dos dados ao longo da pipeline do Transformer",
   "id": "349ca7a79f24badf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T15:27:51.144229Z",
     "start_time": "2025-07-21T15:26:24.269025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DataLoader\n",
    "\n",
    "test_dataloader = data_loader_f(batch_size=2, num_spectra=10)\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    mz_batch, int_batch, attention_mask_batch, batch_spectrum_ids, precursor_mask_batch = batch\n",
    "    \n",
    "    \n",
    "    print(f' mz_batch: {mz_batch.shape}')\n",
    "    print(f' int_batch: {int_batch.shape}')\n",
    "    print(f' attention_mask_batch: {attention_mask_batch.shape}')\n",
    "    print(f' precursor_mz_batch: {precursor_mask_batch.shape}')\n",
    "    \n",
    "    break\n",
    "    \n",
    "    # Esperado [batch_size, max_seq_len]"
   ],
   "id": "330b6f4701b0fd2e",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = EncoderTransformer(vocab_size=vocab_size, d_model=d_model, nhead=4, num_layers=4, dropout_rate=0.1)\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    mz_batch, int_batch, attention_mask_batch, batch_spectrum_ids, precursor_mask_batch = batch\n",
    "    \n",
    "    try:\n",
    "        output = model(mz_batch, int_batch, attention_mask_batch)\n",
    "        print(f\" Output shape: {output.shape}\")  # Esperado: [batch_size, 2048]\n",
    "        print(f\" Output range: {output.min().item():.4f} to {output.max().item():.4f}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f'Erro: {e}')\n",
    "        break"
   ],
   "id": "44d99e525d4d5c2a",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
