{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Transformer Model Data Preparation Workflow",
   "id": "9b4d9a25d3fc9dac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This notebook documents the initial pipeline for mass spectrometry data preparation and preprocessing, which is essential for feeding our future Transformer model.\n",
    "\n",
    "We start by loading and processing MGF files, applying a series of filters and transformations to ensure the quality and appropriate format of the data."
   ],
   "id": "6a69d1137df79e62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The first step involves validating the MGF file path (**path_check**) and loading the raw spectra. The **mgf_get_spectra** function is responsible for reading the MGF file and extracting each spectrum's data",
   "id": "cedc79057b837e53"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-27T15:00:03.175377Z",
     "start_time": "2025-06-27T15:00:01.510704Z"
    }
   },
   "source": [
    "from src.utils import *\n",
    "from src.config import *\n",
    "from src.mgf_tools.mgf_get import * "
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T15:00:03.184952Z",
     "start_time": "2025-06-27T15:00:03.178390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mgf_data = r\"/Users/carla/PycharmProjects/Mestrado/Transformer-Based-Models-for-Chemical-Fingerprint-Prediction/datasets/raw/cleaned_gnps_library.mgf\"\n",
    "\n",
    "path_check(mgf_data)"
   ],
   "id": "6dca8e4786c6f88c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T15:03:50.870509Z",
     "start_time": "2025-06-27T15:00:03.522768Z"
    }
   },
   "cell_type": "code",
   "source": "mgf_spect= mgf_get_spectra(mgf_data, num_spectra=5)",
   "id": "a781ab36f38a82b7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This is the core phase of transforming the raw data. The **mgf_deconvoluter** function iterates over each loaded spectrum, applying a series of cleaning and tokenization steps via the **mgf_spectrum_deconvoluter**",
   "id": "2439e5b290345094"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T15:03:50.920308Z",
     "start_time": "2025-06-27T15:03:50.872516Z"
    }
   },
   "cell_type": "code",
   "source": "x = mgf_deconvoluter(mgf_data=mgf_spect, mz_vocabs=mz_vocabs, min_num_peaks=5, max_num_peaks=max_num_peaks, noise_rmv_threshold=0.01, mass_error=0.01, log=True)",
   "id": "aae912e960a915d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] Rejected spectrum: 500\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The **mgf_deconvoluter** function returns a list of tuples, where each tuple (spectrum_id, tokenized_mz, tokenized_precursor, intensities) represents a spectrum that has successfully passed through the entire preprocessing pipeline.",
   "id": "cfb65b4d21c7ecf5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T15:07:53.384628Z",
     "start_time": "2025-06-27T15:07:53.377589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if len(x) > 0:\n",
    "    spectrum_tuple = x[2]\n",
    "\n",
    "    spectrum_id, tokenized_mz, tokenized_precursor, intensities = spectrum_tuple\n",
    "\n",
    "    print(f\"\\nTokenised spectrum details:\")\n",
    "    print(f\"Spectrum ID: {spectrum_id}\")\n",
    "    print(f\"Number of m/z tokens: {len(tokenized_mz)}\")\n",
    "    print(f\"Number of intensities: {len(intensities)}\")\n",
    "    print(f\"Precursor token: {tokenized_precursor}\")\n",
    "\n",
    "else:\n",
    "    print(\"No spectrum passed through the filters and was processed\")"
   ],
   "id": "1d9062d6f986173c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenised spectrum details:\n",
      "Spectrum ID: CCMSLIB00000001555\n",
      "Number of m/z tokens: 15\n",
      "Number of intensities: 15\n",
      "Precursor token: 6641\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
